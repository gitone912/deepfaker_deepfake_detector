{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-14 12:52:36.834314: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tensorflow.keras.preprocessing import image \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Program To Read video \n",
    "# and Extract Frames \n",
    "\n",
    "import os\n",
    "import cv2 \n",
    "\n",
    "# Function to extract frames \n",
    "def FrameCapture(path): \n",
    "\n",
    "    # Path to video file \n",
    "    vidObj = cv2.VideoCapture(path) \n",
    "\n",
    "    # Used as counter variable \n",
    "    count = 0\n",
    "\n",
    "    # checks whether frames were extracted \n",
    "    success = 1\n",
    "\n",
    "    # Create frames directory if it doesn't exist\n",
    "    if not os.path.exists(\"frames\"):\n",
    "        os.makedirs(\"frames\")\n",
    "\n",
    "    while success: \n",
    "\n",
    "        # vidObj object calls read \n",
    "        # function extract frames \n",
    "        success, image = vidObj.read() \n",
    "\n",
    "        # Check if the image is empty\n",
    "        if not success:\n",
    "            break\n",
    "\n",
    "        # Saves the frames with frame-count \n",
    "        # Modifying to save frames with 'frame' prefix and count as multiples of 10\n",
    "        frames_num = 20\n",
    "        if count % frames_num == 0:\n",
    "            cv2.imwrite(\"frames/frame%d.jpg\" % (count), image) \n",
    "\n",
    "        count += 1\n",
    "\n",
    "\n",
    "\n",
    "FrameCapture(\"/Users/pranaymishra/Desktop/deepfake/Dictators - Vladimir Putin.mp4\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = tf.keras.models.load_model('deepfake_detection_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n",
      "frame540.jpg: Fake (Confidence: 0.593668520450592)\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "frame420.jpg: Fake (Confidence: 0.612930417060852)\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "frame780.jpg: Real (Confidence: 0.4413667321205139)\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "frame580.jpg: Fake (Confidence: 0.5973744988441467)\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "frame620.jpg: Real (Confidence: 0.43562543392181396)\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "frame740.jpg: Real (Confidence: 0.4413853883743286)\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "frame220.jpg: Fake (Confidence: 0.613996684551239)\n",
      "1/1 [==============================] - 0s 108ms/step\n",
      "frame40.jpg: Fake (Confidence: 0.6271325945854187)\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "frame340.jpg: Fake (Confidence: 0.5990725159645081)\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "frame180.jpg: Fake (Confidence: 0.6028731465339661)\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "frame80.jpg: Fake (Confidence: 0.6228286623954773)\n",
      "1/1 [==============================] - 0s 157ms/step\n",
      "frame380.jpg: Fake (Confidence: 0.5894466638565063)\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "frame140.jpg: Fake (Confidence: 0.5860578417778015)\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "frame480.jpg: Fake (Confidence: 0.6141152381896973)\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "frame640.jpg: Real (Confidence: 0.4356723427772522)\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "frame720.jpg: Real (Confidence: 0.4412136673927307)\n",
      "1/1 [==============================] - 0s 132ms/step\n",
      "frame520.jpg: Fake (Confidence: 0.6080321669578552)\n",
      "1/1 [==============================] - 0s 137ms/step\n",
      "frame440.jpg: Fake (Confidence: 0.6003139615058899)\n",
      "1/1 [==============================] - 0s 138ms/step\n",
      "frame680.jpg: Real (Confidence: 0.47970935702323914)\n",
      "1/1 [==============================] - 0s 144ms/step\n",
      "frame280.jpg: Fake (Confidence: 0.5889016389846802)\n",
      "1/1 [==============================] - 0s 144ms/step\n",
      "frame120.jpg: Fake (Confidence: 0.6106230020523071)\n",
      "1/1 [==============================] - 0s 150ms/step\n",
      "frame240.jpg: Fake (Confidence: 0.595904529094696)\n",
      "1/1 [==============================] - 0s 145ms/step\n",
      "frame20.jpg: Fake (Confidence: 0.6397573947906494)\n",
      "1/1 [==============================] - 0s 226ms/step\n",
      "frame320.jpg: Fake (Confidence: 0.5909369587898254)\n",
      "1/1 [==============================] - 0s 133ms/step\n",
      "frame700.jpg: Real (Confidence: 0.47966477274894714)\n",
      "1/1 [==============================] - 0s 134ms/step\n",
      "frame660.jpg: Real (Confidence: 0.47969210147857666)\n",
      "1/1 [==============================] - 0s 131ms/step\n",
      "frame460.jpg: Fake (Confidence: 0.6035073399543762)\n",
      "1/1 [==============================] - 0s 136ms/step\n",
      "frame500.jpg: Fake (Confidence: 0.5968018174171448)\n",
      "1/1 [==============================] - 0s 247ms/step\n",
      "frame100.jpg: Fake (Confidence: 0.6048609614372253)\n",
      "1/1 [==============================] - 0s 126ms/step\n",
      "frame0.jpg: Fake (Confidence: 0.6192734837532043)\n",
      "1/1 [==============================] - 0s 132ms/step\n",
      "frame300.jpg: Fake (Confidence: 0.5958378911018372)\n",
      "1/1 [==============================] - 0s 236ms/step\n",
      "frame260.jpg: Fake (Confidence: 0.5874475836753845)\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "frame400.jpg: Fake (Confidence: 0.6098883748054504)\n",
      "1/1 [==============================] - 0s 126ms/step\n",
      "frame560.jpg: Fake (Confidence: 0.591942548751831)\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "frame760.jpg: Real (Confidence: 0.4413853883743286)\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "frame600.jpg: Real (Confidence: 0.4354844391345978)\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "frame360.jpg: Fake (Confidence: 0.5908012986183167)\n",
      "1/1 [==============================] - 0s 143ms/step\n",
      "frame60.jpg: Fake (Confidence: 0.6575506925582886)\n",
      "1/1 [==============================] - 0s 135ms/step\n",
      "frame200.jpg: Fake (Confidence: 0.606397271156311)\n",
      "1/1 [==============================] - 0s 135ms/step\n",
      "frame160.jpg: Fake (Confidence: 0.6115256547927856)\n",
      "Average Confidence: 0.5670250244438648\n",
      "The video is predicted as a deepfake.\n"
     ]
    }
   ],
   "source": [
    "def evaluate_frames(directory):\n",
    "    total_confidence = 0\n",
    "    num_frames = 0\n",
    "\n",
    "    # Iterate through frames in the directory\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\".jpg\"):\n",
    "            img_path = os.path.join(directory, filename)\n",
    "            img = image.load_img(img_path, target_size=(224, 224))\n",
    "            img_array = image.img_to_array(img)\n",
    "            img_array = np.expand_dims(img_array, axis=0)\n",
    "            img_array /= 255.0  # Normalize pixel values\n",
    "\n",
    "            # Predict\n",
    "            confidence = loaded_model.predict(img_array)[0][0]\n",
    "            total_confidence += confidence\n",
    "            num_frames += 1\n",
    "\n",
    "            # Print result\n",
    "            if confidence >= 0.5:\n",
    "                print(f\"{filename}: Fake (Confidence: {confidence})\")\n",
    "            else:\n",
    "                print(f\"{filename}: Real (Confidence: {confidence})\")\n",
    "\n",
    "    # Calculate average confidence\n",
    "    if num_frames > 0:\n",
    "        average_confidence = total_confidence / num_frames\n",
    "        print(f\"Average Confidence: {average_confidence}\")\n",
    "        if average_confidence >= 0.5:\n",
    "            print(\"The video is predicted as a deepfake.\")\n",
    "        else:\n",
    "            print(\"The video is predicted as real.\")\n",
    "    else:\n",
    "        print(\"No frames found in the directory.\")\n",
    "\n",
    "\n",
    "# Call the function to evaluate frames in the 'frames' directory\n",
    "evaluate_frames(\"frames\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
